<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: September 26, 2024 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=stylesheet href=/css/wowchemy.c3e98bbf812b5579a7a3e46d1066de01.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><script async src="https://www.googletagmanager.com/gtag/js?id=G-X77MT4WG8J"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","G-X77MT4WG8J",{}),gtag("set",{cookie_flags:"SameSite=None;Secure"}),document.addEventListener("click",onClickCallback,!1)</script><meta name=author content="Sen Na"><meta name=description content="Graph representation learning is a ubiquitous task in machine learning where the goal is to embed each vertex into a low-dimensional vector space. We consider the bipartite graph and formalize its representation learning problem as a statistical estimation problem of parameters in a semiparametric exponential family distribution: the bipartite graph is assumed to be generated by a semiparametric exponential family distribution, whose parametric component is given by the proximity of outputs of two one-layer neural networks that take high-dimensional features as inputs, while nonparametric (nuisance) component is the base measure. In this setting, the representation learning problem is equivalent to recovering the weight matrices, and the main challenges of estimation arise from the nonlinearity of activation functions and the nonparametric nuisance component of the distribution. To overcome these challenges, we propose a pseudo-likelihood objective based on the rank-order decomposition technique and show that the proposed objective is strongly convex in a neighborhood around the ground truth, so that a gradient descent-based method achieves linear convergence rate. Moreover, we prove that the sample complexity of the problem is linear in dimensions (up to logarithmic factors), which is consistent with parametric Gaussian models. However, our estimator is robust to any model misspecification within the exponential family, which is validated in extensive experiments."><link rel=alternate hreflang=en-us href=https://senna1128.github.io/publication/pubs/na-2020-semiparametric/><link rel=canonical href=https://senna1128.github.io/publication/pubs/na-2020-semiparametric/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#3385FF"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://senna1128.github.io/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="SEN NA"><meta property="og:url" content="https://senna1128.github.io/publication/pubs/na-2020-semiparametric/"><meta property="og:title" content="Semiparametric Nonlinear Bipartite Graph Representation Learning with Provable Guarantees | SEN NA"><meta property="og:description" content="Graph representation learning is a ubiquitous task in machine learning where the goal is to embed each vertex into a low-dimensional vector space. We consider the bipartite graph and formalize its representation learning problem as a statistical estimation problem of parameters in a semiparametric exponential family distribution: the bipartite graph is assumed to be generated by a semiparametric exponential family distribution, whose parametric component is given by the proximity of outputs of two one-layer neural networks that take high-dimensional features as inputs, while nonparametric (nuisance) component is the base measure. In this setting, the representation learning problem is equivalent to recovering the weight matrices, and the main challenges of estimation arise from the nonlinearity of activation functions and the nonparametric nuisance component of the distribution. To overcome these challenges, we propose a pseudo-likelihood objective based on the rank-order decomposition technique and show that the proposed objective is strongly convex in a neighborhood around the ground truth, so that a gradient descent-based method achieves linear convergence rate. Moreover, we prove that the sample complexity of the problem is linear in dimensions (up to logarithmic factors), which is consistent with parametric Gaussian models. However, our estimator is robust to any model misspecification within the exponential family, which is validated in extensive experiments."><meta property="og:image" content="https://senna1128.github.io/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-02-28T22:15:07+00:00"><meta property="article:modified_time" content="2023-02-28T14:15:07-08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://senna1128.github.io/publication/pubs/na-2020-semiparametric/"},"headline":"Semiparametric Nonlinear Bipartite Graph Representation Learning with Provable Guarantees","datePublished":"2023-02-28T22:15:07Z","dateModified":"2023-02-28T14:15:07-08:00","author":{"@type":"Person","name":"Sen Na"},"publisher":{"@type":"Organization","name":"SEN NA","logo":{"@type":"ImageObject","url":"https://senna1128.github.io/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_192x192_fill_lanczos_center_3.png"}},"description":"Graph representation learning is a ubiquitous task in machine learning where the goal is to embed each vertex into a low-dimensional vector space. We consider the bipartite graph and formalize its representation learning problem as a statistical estimation problem of parameters in a semiparametric exponential family distribution: the bipartite graph is assumed to be generated by a semiparametric exponential family distribution, whose parametric component is given by the proximity of outputs of two one-layer neural networks that take high-dimensional features as inputs, while nonparametric (nuisance) component is the base measure. In this setting, the representation learning problem is equivalent to recovering the weight matrices, and the main challenges of estimation arise from the nonlinearity of activation functions and the nonparametric nuisance component of the distribution. To overcome these challenges, we propose a pseudo-likelihood objective based on the rank-order decomposition technique and show that the proposed objective is strongly convex in a neighborhood around the ground truth, so that a gradient descent-based method achieves linear convergence rate. Moreover, we prove that the sample complexity of the problem is linear in dimensions (up to logarithmic factors), which is consistent with parametric Gaussian models. However, our estimator is robust to any model misspecification within the exponential family, which is validated in extensive experiments."}</script><title>Semiparametric Nonlinear Bipartite Graph Representation Learning with Provable Guarantees | SEN NA</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=af8895b43efb6957c9d2ccc62ea4e649><script src=/js/wowchemy-init.min.6c97b441ea640ebf7a15c2a15a80b670.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>SEN NA</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>SEN NA</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/research/><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/papers/><span>Papers</span></a></li><li class=nav-item><a class=nav-link href=/service/><span>Service</span></a></li><li class=nav-item><a class=nav-link href=/misc/><span>Misc</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li><li class=nav-item><a class=nav-link href=/uploads/CV_SenNa.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Semiparametric Nonlinear Bipartite Graph Representation Learning with Provable Guarantees</h1><div class=article-metadata><div><span class=author-highlighted><a href=/authors/sen-na/>Sen Na</a></span>, <span><a href=/authors/yuwei-luo/>Yuwei Luo</a></span>, <span><a href=/authors/zhuoran-yang/>Zhuoran Yang</a></span>, <span><a href=/authors/zhaoran-wang/>Zhaoran Wang</a></span>, <span><a href=/authors/mladen-kolar/>Mladen Kolar</a></span></div><span class=article-date>May 2020</span></div><div class="btn-links mb-3"><a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/pubs/na-2020-semiparametric/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header" href=http://proceedings.mlr.press/v119/na20a.html target=_blank rel=noopener>URL</a>
<a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/2003.01013 target=_blank rel=noopener>arXiv</a></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>Graph representation learning is a ubiquitous task in machine learning where the goal is to embed each vertex into a low-dimensional vector space. We consider the bipartite graph and formalize its representation learning problem as a statistical estimation problem of parameters in a semiparametric exponential family distribution: the bipartite graph is assumed to be generated by a semiparametric exponential family distribution, whose parametric component is given by the proximity of outputs of two one-layer neural networks that take high-dimensional features as inputs, while nonparametric (nuisance) component is the base measure. In this setting, the representation learning problem is equivalent to recovering the weight matrices, and the main challenges of estimation arise from the nonlinearity of activation functions and the nonparametric nuisance component of the distribution. To overcome these challenges, we propose a pseudo-likelihood objective based on the rank-order decomposition technique and show that the proposed objective is strongly convex in a neighborhood around the ground truth, so that a gradient descent-based method achieves linear convergence rate. Moreover, we prove that the sample complexity of the problem is linear in dimensions (up to logarithmic factors), which is consistent with parametric Gaussian models. However, our estimator is robust to any model misspecification within the exponential family, which is validated in extensive experiments.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#2>Journal/Conference paper</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9"><em>International Conference on Machine Learning</em></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/stat.ml/>stat.ML</a>
<a class="badge badge-light" href=/tag/cs.lg/>cs.LG</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fpubs%2Fna-2020-semiparametric%2F&amp;text=Semiparametric+Nonlinear+Bipartite+Graph+Representation+Learning+with+Provable+Guarantees" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fpubs%2Fna-2020-semiparametric%2F&amp;t=Semiparametric+Nonlinear+Bipartite+Graph+Representation+Learning+with+Provable+Guarantees" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Semiparametric%20Nonlinear%20Bipartite%20Graph%20Representation%20Learning%20with%20Provable%20Guarantees&amp;body=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fpubs%2Fna-2020-semiparametric%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fpubs%2Fna-2020-semiparametric%2F&amp;title=Semiparametric+Nonlinear+Bipartite+Graph+Representation+Learning+with+Provable+Guarantees" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Semiparametric+Nonlinear+Bipartite+Graph+Representation+Learning+with+Provable+Guarantees%20https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fpubs%2Fna-2020-semiparametric%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fpubs%2Fna-2020-semiparametric%2F&amp;title=Semiparametric+Nonlinear+Bipartite+Graph+Representation+Learning+with+Provable+Guarantees" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://senna1128.github.io><img class="avatar mr-3 avatar-circle" src=/authors/sen-na/avatar_hu9cbe1d0992b54ee338d638ca2d7cdacc_218739_270x270_fill_q75_lanczos_center.jpeg alt="Sen Na"></a><div class=media-body><h5 class=card-title><a href=https://senna1128.github.io>Sen Na</a></h5><h6 class=card-subtitle>Assistant Professor in ISyE</h6><p class=card-text>Sen Na is an Assistant Professor in the School of Industrial and Systems Engineering at Georgia Tech. Prior to joining ISyE, he was a postdoctoral researcher in the statistics department and ICSI at UC Berkeley. His research interests broadly lie in the mathematical foundations of data science, with topics including high-dimensional statistics, graphical models, semiparametric models, optimal control, and large-scale and stochastic nonlinear optimization. He is also interested in applying machine learning methods to biology, neuroscience, and engineering.</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=nwLgyLMAAAAJ&amp;hl=en&amp;authuser=1" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/senna1128 target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/sen-na-38a8a9132/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/uploads/CV_SenNa.pdf><i class="ai ai-cv"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/authors/yuwei-luo/><img class="avatar mr-3 avatar-circle" src=/authors/yuwei-luo/avatar_hu3c89055f1a5be6d639c43ff0bc0cc02c_52627_270x270_fill_q75_lanczos_center.jpg alt="Yuwei Luo"></a><div class=media-body><h5 class=card-title><a href=/authors/yuwei-luo/>Yuwei Luo</a></h5><h6 class=card-subtitle>MS Student (2019-2020)</h6><p class=card-text>Yuwei Luo received his M.S. degree in Statistics at University of Chicago in March 2020. Prior to graduate school, he received B.S.degree in Mathematics at University of Science and Technology of China (USTC) in June 2018. His research interests include reinforcement learning, control, optimization and network analysis. Yuwei is continuing his education as a PhD student at Stanford University.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:yuweiluo@uchicago.edu><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=Jb8r920AAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://www.linkedin.com/in/yuwei-luo-40b7a11a3/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/authors/zhuoran-yang/><img class="avatar mr-3 avatar-circle" src=/authors/zhuoran-yang/avatar_huc7ffec3f876e7c4057b34ed95a4e4083_10822_270x270_fill_q75_lanczos_center.jpg alt="Zhuoran Yang"></a><div class=media-body><h5 class=card-title><a href=/authors/zhuoran-yang/>Zhuoran Yang</a></h5><h6 class=card-subtitle>Assistant Professor of Statistics and Data Science</h6><p class=card-text>Zhuoran Yang is an Assistant Professor of Statistics and Data Science at Yale University. His research interests lie in the interface between machine learning, statistics and optimization. The primary goal of his research is to design efficient learning algorithms for large-scale decision making problems that arise in reinforcement learning and stochastic games, with both statistical and computational guarantees.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:zy6@princeton.edu><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=k7NgVSUAAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://www.princeton.edu/~zy6/current/zhuoranCV.pdf target=_blank rel=noopener><i class="ai ai-cv"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/authors/zhaoran-wang/><img class="avatar mr-3 avatar-circle" src=/authors/zhaoran-wang/avatar_huaf4b8c68dd7d3826a7ad93691d58fc64_65509_270x270_fill_q75_lanczos_center.jpg alt="Zhaoran Wang"></a><div class=media-body><h5 class=card-title><a href=/authors/zhaoran-wang/>Zhaoran Wang</a></h5><h6 class=card-subtitle>Associate Professor in Industrial Engineering & Management Sciences</h6><p class=card-text>Zhaoran Wang is an Associate Professor in the Departments of Industrial Engineering & Management Sciences and Computer Science at Northwestern University. His research is to develop a new generation of data-driven decision-making methods, theory, and systems, which tailor artificial intelligence towards addressing pressing societal challenges.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:zhaoranwang@gmail.com><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=HSx0BgQAAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/authors/mladen-kolar/><img class="avatar mr-3 avatar-circle" src=/authors/mladen-kolar/avatar_hu32e11a043cd1a9e01f4e7723d356fc61_1849556_270x270_fill_q75_lanczos_center.jpg alt="Mladen Kolar"></a><div class=media-body><h5 class=card-title><a href=/authors/mladen-kolar/>Mladen Kolar</a></h5><h6 class=card-subtitle>Associate Professor of Econometrics and Statistics</h6><p class=card-text>Mladen Kolar is an Associate Professor of Econometrics and Statistics at the University of Chicago Booth School of Business. His research is focused on high-dimensional statistical methods, graphical models, varying-coefficient models and data mining, driven by the need to uncover interesting and scientifically meaningful structures from observational data.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:Mladen.Kolar@ChicagoBooth.edu><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?hl=en&amp;user=9LcxwsMAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/mlakolar target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://mkolar.coffeejunkies.org/files/cv.pdf target=_blank rel=noopener><i class="ai ai-cv"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by></p></footer></div></div><script src=/js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.74208d2eb9bcccbceb498308551adecc.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.dfc4c6eaa55c53d2bb7ff2e18abf41a0.js type=module></script></body></html>