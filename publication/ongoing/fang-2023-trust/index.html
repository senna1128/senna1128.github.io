<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: September 26, 2024 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=stylesheet href=/css/wowchemy.c3e98bbf812b5579a7a3e46d1066de01.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><script async src="https://www.googletagmanager.com/gtag/js?id=G-X77MT4WG8J"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","G-X77MT4WG8J",{}),gtag("set",{cookie_flags:"SameSite=None;Secure"}),document.addEventListener("click",onClickCallback,!1)</script><meta name=author content="Sen Na"><meta name=description content=" We design a trust-region sequential quadratic programming (TR-SQP) method to find both **first- and second-order** stationary points for optimization problems with a stochastic objective and deterministic equality constraints. We name our method TR-SQP for STochastic Optimization with Random Models (TR-SQP-STORM). In each iteration, the algorithm constructs random models that require estimates of the objective value, gradient, and Hessian to satisfy adaptive accuracy conditions with a fixed probability. We introduce a novel reliability parameter, based on which we define reliable and unreliable iterations and adjust accuracy conditions accordingly. The reliability parameter equips the random models with extra flexibility to reduce the sample size at each step. To find first-order stationary points, we compute **gradient-steps** by employing the **adaptive relaxation technique** proposed by [Fang et al., 2022](/publication/preprints/fang-2022-fully). To find second-order stationary points, we design **eigen-steps** to explore the negative curvature of the reduced Lagrangian Hessian, with additional **second-order correctional steps** performed when necessary. Under reasonable assumptions, we establish both first- and second-order global convergence guarantees: with probability one, the TR-SQP-STORM iteration sequence converges to the first-order stationary point, with a subsequence converging to the second-order stationary point. We apply our method to a subset of problems in CUTEst set and on constrained Logistic regression problems to demonstrate its promising empirical performance."><link rel=alternate hreflang=en-us href=https://senna1128.github.io/publication/ongoing/fang-2023-trust/><link rel=canonical href=https://senna1128.github.io/publication/ongoing/fang-2023-trust/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#3385FF"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://senna1128.github.io/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="SEN NA"><meta property="og:url" content="https://senna1128.github.io/publication/ongoing/fang-2023-trust/"><meta property="og:title" content="Trust-Region Sequential Quadratic Programming for Stochastic Optimization with Random Models | SEN NA"><meta property="og:description" content=" We design a trust-region sequential quadratic programming (TR-SQP) method to find both **first- and second-order** stationary points for optimization problems with a stochastic objective and deterministic equality constraints. We name our method TR-SQP for STochastic Optimization with Random Models (TR-SQP-STORM). In each iteration, the algorithm constructs random models that require estimates of the objective value, gradient, and Hessian to satisfy adaptive accuracy conditions with a fixed probability. We introduce a novel reliability parameter, based on which we define reliable and unreliable iterations and adjust accuracy conditions accordingly. The reliability parameter equips the random models with extra flexibility to reduce the sample size at each step. To find first-order stationary points, we compute **gradient-steps** by employing the **adaptive relaxation technique** proposed by [Fang et al., 2022](/publication/preprints/fang-2022-fully). To find second-order stationary points, we design **eigen-steps** to explore the negative curvature of the reduced Lagrangian Hessian, with additional **second-order correctional steps** performed when necessary. Under reasonable assumptions, we establish both first- and second-order global convergence guarantees: with probability one, the TR-SQP-STORM iteration sequence converges to the first-order stationary point, with a subsequence converging to the second-order stationary point. We apply our method to a subset of problems in CUTEst set and on constrained Logistic regression problems to demonstrate its promising empirical performance."><meta property="og:image" content="https://senna1128.github.io/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-02-28T00:00:00+00:00"><meta property="article:modified_time" content="2023-02-28T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://senna1128.github.io/publication/ongoing/fang-2023-trust/"},"headline":"Trust-Region Sequential Quadratic Programming for Stochastic Optimization with Random Models","datePublished":"2023-02-28T00:00:00Z","dateModified":"2023-02-28T00:00:00Z","author":{"@type":"Person","name":"Yuchen Fang"},"publisher":{"@type":"Organization","name":"SEN NA","logo":{"@type":"ImageObject","url":"https://senna1128.github.io/media/icon_hubc7f07b0b42b02f4dee90e6a014d6db7_1542881_192x192_fill_lanczos_center_3.png"}},"description":" We design a trust-region sequential quadratic programming (TR-SQP) method to find both **first- and second-order** stationary points for optimization problems with a stochastic objective and deterministic equality constraints. We name our method TR-SQP for STochastic Optimization with Random Models (TR-SQP-STORM). In each iteration, the algorithm constructs random models that require estimates of the objective value, gradient, and Hessian to satisfy adaptive accuracy conditions with a fixed probability. We introduce a novel reliability parameter, based on which we define reliable and unreliable iterations and adjust accuracy conditions accordingly. The reliability parameter equips the random models with extra flexibility to reduce the sample size at each step. To find first-order stationary points, we compute **gradient-steps** by employing the **adaptive relaxation technique** proposed by [Fang et al., 2022](/publication/preprints/fang-2022-fully). To find second-order stationary points, we design **eigen-steps** to explore the negative curvature of the reduced Lagrangian Hessian, with additional **second-order correctional steps** performed when necessary. Under reasonable assumptions, we establish both first- and second-order global convergence guarantees: with probability one, the TR-SQP-STORM iteration sequence converges to the first-order stationary point, with a subsequence converging to the second-order stationary point. We apply our method to a subset of problems in CUTEst set and on constrained Logistic regression problems to demonstrate its promising empirical performance."}</script><title>Trust-Region Sequential Quadratic Programming for Stochastic Optimization with Random Models | SEN NA</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=5cc96091cd016ec735c1ed29314c1f30><script src=/js/wowchemy-init.min.6c97b441ea640ebf7a15c2a15a80b670.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>SEN NA</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>SEN NA</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/research/><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/papers/><span>Papers</span></a></li><li class=nav-item><a class=nav-link href=/service/><span>Service</span></a></li><li class=nav-item><a class=nav-link href=/misc/><span>Misc</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li><li class=nav-item><a class=nav-link href=/uploads/CV_SenNa.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Trust-Region Sequential Quadratic Programming for Stochastic Optimization with Random Models</h1><div class=article-metadata><div><span><a href=/authors/yuchen-fang/>Yuchen Fang</a></span>, <span class=author-highlighted><a href=/authors/sen-na/>Sen Na</a></span>, <span><a href=/authors/michael-w.-mahoney/>Michael W. Mahoney</a></span>, <span><a href=/authors/mladen-kolar/>Mladen Kolar</a></span></div><span class=article-date>February 2023</span></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>We design a trust-region sequential quadratic programming (TR-SQP) method to find both <strong>first- and second-order</strong> stationary points for optimization problems with a stochastic objective and deterministic equality constraints. We name our method TR-SQP for STochastic Optimization with Random Models (TR-SQP-STORM). In each iteration, the algorithm constructs random models that require estimates of the objective value, gradient, and Hessian to satisfy adaptive accuracy conditions with a fixed probability. We introduce a novel reliability parameter, based on which we define reliable and unreliable iterations and adjust accuracy conditions accordingly. The reliability parameter equips the random models with extra flexibility to reduce the sample size at each step. To find first-order stationary points, we compute <strong>gradient-steps</strong> by employing the <strong>adaptive relaxation technique</strong> proposed by <a href=/publication/preprints/fang-2022-fully>Fang et al., 2022</a>. To find second-order stationary points, we design <strong>eigen-steps</strong> to explore the negative curvature of the reduced Lagrangian Hessian, with additional <strong>second-order correctional steps</strong> performed when necessary. Under reasonable assumptions, we establish both first- and second-order global convergence guarantees: with probability one, the TR-SQP-STORM iteration sequence converges to the first-order stationary point, with a subsequence converging to the second-order stationary point. We apply our method to a subset of problems in CUTEst set and on constrained Logistic regression problems to demonstrate its promising empirical performance.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#4>Ongoing work</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9"><em>A short note is accepted by 2022 NeurIPS Higher-Order Optimization in Machine Learning (HOO) workshop</em></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/math.oc/>math.OC</a>
<a class="badge badge-light" href=/tag/cs.na/>cs.NA</a>
<a class="badge badge-light" href=/tag/math.na/>math.NA</a>
<a class="badge badge-light" href=/tag/stat.co/>stat.CO</a>
<a class="badge badge-light" href=/tag/stat.ml/>stat.ML</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fongoing%2Ffang-2023-trust%2F&amp;text=Trust-Region+Sequential+Quadratic+Programming+for+Stochastic+Optimization+with+Random+Models" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fongoing%2Ffang-2023-trust%2F&amp;t=Trust-Region+Sequential+Quadratic+Programming+for+Stochastic+Optimization+with+Random+Models" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Trust-Region%20Sequential%20Quadratic%20Programming%20for%20Stochastic%20Optimization%20with%20Random%20Models&amp;body=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fongoing%2Ffang-2023-trust%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fongoing%2Ffang-2023-trust%2F&amp;title=Trust-Region+Sequential+Quadratic+Programming+for+Stochastic+Optimization+with+Random+Models" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Trust-Region+Sequential+Quadratic+Programming+for+Stochastic+Optimization+with+Random+Models%20https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fongoing%2Ffang-2023-trust%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fsenna1128.github.io%2Fpublication%2Fongoing%2Ffang-2023-trust%2F&amp;title=Trust-Region+Sequential+Quadratic+Programming+for+Stochastic+Optimization+with+Random+Models" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=/authors/yuchen-fang/><img class="avatar mr-3 avatar-circle" src=/authors/yuchen-fang/avatar_huee8f55e58bd34c71d98ae423aa82594e_160144_270x270_fill_q75_lanczos_center.jpg alt="Yuchen Fang"></a><div class=media-body><h5 class=card-title><a href=/authors/yuchen-fang/>Yuchen Fang</a></h5><h6 class=card-subtitle>MS in Computational and Applied Math (2021-2023)</h6><p class=card-text>Yuchen Fang is a PhD student in the mathematics department at UC Berkeley. He was a master student in the Computational and Applied Math program at UChicago, where he worked with Mladen Kolar and Sen Na on stochastic nonlinear optimization. His research interests include numerical linear algebra, high-dimensional statistics, statistical learning, and mathematical finance.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:frankycfang@outlook.com><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?hl=en&amp;user=OtsrAMYAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/ychenfang target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://ychenfang.github.io/cv/ target=_blank rel=noopener><i class="ai ai-cv"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=https://senna1128.github.io><img class="avatar mr-3 avatar-circle" src=/authors/sen-na/avatar_hu9cbe1d0992b54ee338d638ca2d7cdacc_218739_270x270_fill_q75_lanczos_center.jpeg alt="Sen Na"></a><div class=media-body><h5 class=card-title><a href=https://senna1128.github.io>Sen Na</a></h5><h6 class=card-subtitle>Assistant Professor in ISyE</h6><p class=card-text>Sen Na is an Assistant Professor in the School of Industrial and Systems Engineering at Georgia Tech. Prior to joining ISyE, he was a postdoctoral researcher in the statistics department and ICSI at UC Berkeley. His research interests broadly lie in the mathematical foundations of data science, with topics including high-dimensional statistics, graphical models, semiparametric models, optimal control, and large-scale and stochastic nonlinear optimization. He is also interested in applying machine learning methods to biology, neuroscience, and engineering.</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=nwLgyLMAAAAJ&amp;hl=en&amp;authuser=1" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/senna1128 target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/sen-na-38a8a9132/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/uploads/CV_SenNa.pdf><i class="ai ai-cv"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/authors/michael-w.-mahoney/><img class="avatar mr-3 avatar-circle" src=/authors/michael-w.-mahoney/avatar_hua8c0263d924e30f81bd987b39dd8c672_60201_270x270_fill_q75_lanczos_center.jpg alt="Michael W. Mahoney"></a><div class=media-body><h5 class=card-title><a href=/authors/michael-w.-mahoney/>Michael W. Mahoney</a></h5><h6 class=card-subtitle>Professor in Statistics and ICSI, Amazon Scholar</h6><p class=card-text>Michael Mahoney is a Professor in the Statistics department and ICSI at UC Berkeley. He is also the director of the NSF/TRIPODS-funded Foundations of Data Analysis (FODA) Institute at UC Berkeley. He works on the algorithmic and statistical aspects of modern large-scale data analysis. Much of his recent research has focused on large-scale machine learning, including randomized matrix algorithms and randomized numerical linear algebra.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:mmahoney@stat.berkeley.edu><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=QXyvv94AAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://www.linkedin.com/in/michael-mahoney-7766708 target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/authors/mladen-kolar/><img class="avatar mr-3 avatar-circle" src=/authors/mladen-kolar/avatar_hu32e11a043cd1a9e01f4e7723d356fc61_1849556_270x270_fill_q75_lanczos_center.jpg alt="Mladen Kolar"></a><div class=media-body><h5 class=card-title><a href=/authors/mladen-kolar/>Mladen Kolar</a></h5><h6 class=card-subtitle>Associate Professor of Econometrics and Statistics</h6><p class=card-text>Mladen Kolar is an Associate Professor of Econometrics and Statistics at the University of Chicago Booth School of Business. His research is focused on high-dimensional statistical methods, graphical models, varying-coefficient models and data mining, driven by the need to uncover interesting and scientifically meaningful structures from observational data.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:Mladen.Kolar@ChicagoBooth.edu><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?hl=en&amp;user=9LcxwsMAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/mlakolar target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://mkolar.coffeejunkies.org/files/cv.pdf target=_blank rel=noopener><i class="ai ai-cv"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by></p></footer></div></div><script src=/js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.74208d2eb9bcccbceb498308551adecc.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.dfc4c6eaa55c53d2bb7ff2e18abf41a0.js type=module></script></body></html>